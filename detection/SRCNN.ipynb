{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51185ee-4b0d-4326-9635-2bdea06dc70d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "\n",
    "# glob.glob(train set의 경로)\n",
    "data = glob.glob(\"./yolov5/data/images/train/*.jpg\")\n",
    "# test에는 cropped image를 우선 모아둔 파일을 지정\n",
    "test = glob.glob(\"./yolov5/final_data_640/images/train/*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d829643-2603-4db3-874b-599d21964fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRdataset(Dataset):\n",
    "\n",
    "    def __init__(self, pth):\n",
    "        self.pth = pth        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pth)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        path = self.pth[idx]\n",
    "        label = cv2.imread(path)\n",
    "        label = cv2.cvtColor(label, cv2.COLOR_BGR2RGB)\n",
    "        # yolo 모델의 학습을 위해서 640 x 640으로 맞춰준다.\n",
    "        label = cv2.resize(label, dsize=(640, 640), interpolation=cv2.INTER_AREA)\n",
    "        # pixel 정규화\n",
    "        label = label.astype(np.float32) / 255.0\n",
    "        # low resolution image를 위해서 Gaussian Blur를 추가\n",
    "        inp = cv2.GaussianBlur(label,(0,0),2)\n",
    "        label = np.transpose(label, (2,0,1))\n",
    "        inp = np.transpose(inp, (2,0,1))\n",
    "\n",
    "        inp, label = torch.tensor(inp, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        return inp, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a23f0c9-a5fa-42a3-aa50-9813a4e282ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터셋은 확보한 원본 이미지 4000여장을 활용\n",
    "train = SRdataset(data[:4000])\n",
    "train_loader = DataLoader(train, batch_size=16)\n",
    "len(train), len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632b6492-06d5-4cb5-859e-23e9652a0a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ = SRdataset(test)\n",
    "test_loader = DataLoader(test_, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f2ad25-dee0-4633-931b-ea9818fce407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우선 low resolution과 label을 체크한다.\n",
    "# 아래의 그림은 input에 해당하는 low resolution image, label에 해당하는 high resolution image\n",
    "i, l = train[0]\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"low resolution image\")\n",
    "plt.imshow(np.transpose(i, (1,2,0)))\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"label image\")\n",
    "plt.imshow(np.transpose(l, (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb6ae51-cbaa-4317-bf34-f991acc4c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # 기본적인 SRCNN 모델 구조를 따랐습니다.\n",
    "        self.conv1 = nn.Conv2d(3, 64, 9, padding=2, padding_mode='replicate')\n",
    "        self.conv2 = nn.Conv2d(64, 32, 1, padding=2, padding_mode='replicate')\n",
    "        self.conv3 = nn.Conv2d(32, 3, 5, padding=2, padding_mode='replicate')\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        torch.nn.init.kaiming_normal_(self.conv1.weight)\n",
    "        torch.nn.init.kaiming_normal_(self.conv2.weight)\n",
    "        torch.nn.init.kaiming_normal_(self.conv3.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8482ef9-3c42-493a-b527-404b9b900d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SRCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98167230-3592-42fb-8771-b18e434a31bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d331b24c-498e-4adb-8929-9b578bc46399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSNR: Super Resolution의 평가 지표\n",
    "import math\n",
    "\n",
    "def psnr(label, outputs, max_val=1.):\n",
    "    label = label.cpu().detach().numpy()\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "    img_diff = outputs - label\n",
    "    rmse = math.sqrt(np.mean((img_diff)**2))\n",
    "    if rmse == 0: # label과 output이 완전히 일치하는 경우\n",
    "        return 100\n",
    "    else:\n",
    "        psnr = 20 * math.log10(max_val/rmse)\n",
    "        return psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e6c282-d3d9-4449-acc9-8d723b877258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 함수\n",
    "def training(model, data_loader):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_psnr = 0.0\n",
    "\n",
    "    for i, (image, label) in enumerate(data_loader):\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        loss = loss_function(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        batch_psnr = psnr(label, outputs)\n",
    "        running_psnr += batch_psnr\n",
    "    \n",
    "    final_loss = running_loss / len(data_loader)\n",
    "    final_psnr = running_psnr / len(data_loader)\n",
    "    return final_loss, final_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c188c9-1a68-4065-a2de-c3062dc91529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "epochs = 20\n",
    "best_psnr = 0\n",
    "train_loss = []\n",
    "train_psnr = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f'Epoch {epoch + 1} of {epochs}')\n",
    "    train_epoch_loss, train_epoch_psnr = training(model, train_loader)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    train_psnr.append(train_epoch_psnr)\n",
    "    if train_epoch_psnr >= best_psnr:\n",
    "        best_psnr = train_epoch_psnr\n",
    "        torch.save(model, \"best_psnr.pt\")\n",
    "    print(f'Train PSNR: {train_epoch_psnr:.3f}')\n",
    "\n",
    "print(\"Best PSNR: {}\".format(best_psnr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f9c38-dddf-4f51-9803-8442d6a22c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 해당 부분은 Cropped image를 model에 통과 시켜 High resolution image를 얻어내고 저장까지 하는 부분이다.\n",
    "cnt = 0\n",
    "with torch.no_grad():\n",
    "    for x, _ in tqdm(test_loader):\n",
    "        x = x.to(device)\n",
    "        output_image = model(x)\n",
    "        output = output_image.cpu().numpy().squeeze()\n",
    "        output = output.astype(np.uint8)\n",
    "        output = np.transpose(output, (1, 2, 0))\n",
    "        output = Image.fromarray(output)\n",
    "        # save(cropped_image 저장 경로)\n",
    "        output.save(test[cnt])\n",
    "        cnt += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
